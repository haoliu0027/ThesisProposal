{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import dstack, hstack\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "import spidev\n",
    "from numpy import interp\n",
    "from time import sleep\n",
    "import RPi.GPIO as GPIO\n",
    "import signal\n",
    "import datetime, time\n",
    "# from threading import _Timer\n",
    "import csv\n",
    "import termios,sys,tty, fcntl, os,select\n",
    "import threading\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "  # data_filenames = ['data_0v3_2.csv','data_1v3_2.csv','data_2v3_2.csv','data_3v3_2.csv','data_7v3_2.csv','data_8v3_2.csv',\n",
    "                    # 'data_9v3_2.csv','data_4v3_3.csv','data_5v3_3.csv','data_6v3_3.csv']\n",
    "  data_filenames = ['data_0_v5_3.csv','data_1_v5_3.csv','data_2_v5_3.csv','data_3_v5_3.csv','data_4_v5_3.csv','data_5_v5_3.csv','data_6_v5_3.csv','data_7_v5_3.csv'\n",
    "  ,'data_8_v5_3.csv','data_9_v5_3.csv']\n",
    "  photodiode_arr = ['6','1','2','3','9','8','7','4','5']\n",
    "  data_frame = []\n",
    "  for i,file in enumerate (data_filenames):\n",
    "    data = pd.read_csv(file)\n",
    "    data_frame.append (data)\n",
    "  data_frame = pd.concat(data_frame, join = 'inner')\n",
    "  data_3D = list()\n",
    "  for i, photodiode_name in enumerate(photodiode_arr):\n",
    "    data_3D.append(data_frame[photodiode_name].values.reshape(-1, ))  \n",
    "  data_3D = dstack(data_3D)\n",
    "  data_3D = data_3D.reshape((-1, 500,9))\n",
    "  data_y = pd.read_csv('label_v5.csv')\n",
    "  result_none = np.where(data_y == -1)\n",
    "  data_y = data_y.drop([data_y.index[260],   data_y.index[891],   data_y.index[892]], axis = 0)\n",
    "  data_3D = np.delete(data_3D, [260, 891, 892 ], axis = 0)\n",
    "  data_y = to_categorical(data_y,num_classes=10)\n",
    "  Xtra,Xval,Ytra,Yval = train_test_split(data_3D,data_y,test_size=0.2,shuffle=True)\n",
    "  return Xtra, Ytra, Xval, Yval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(): \n",
    "  # model.add(GRU(150, input_shape=(n_timesteps,n_features), return_sequences=True))\n",
    "  # model.add(GRU(50))\n",
    "  model.add(GRU(80, input_shape=(n_timesteps,n_features), return_sequences=False))\n",
    "  # model.add(LSTM(80))\n",
    "  # model.add(Dropout(0.2))\n",
    "  # model.add(GRU(150))\n",
    "  # model.add(Bidirectional( GRU(100))) \n",
    "  # model.add(Dropout(0.5))\n",
    "  # model.add(Dense(100, activation='relu'))\n",
    "  model.add(Dense(80, activation='relu'))\n",
    "  model.add(Dense(n_outputs, activation='softmax'))\n",
    "  model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model_checkpoint= ModelCheckpoint('RNN_model_weights.hdf5', save_best_only=True, monitor='val_loss', \n",
    "                                      mode='auto', save_weights_only=True)\n",
    "        # fit network\n",
    "        history = model.fit(trainX, trainy, epochs=epochs, validation_split=0.2, batch_size=batch_size, verbose=verbose)\n",
    "        # evaluate model\n",
    "        _, accuracy = model.evaluate(testX, testy,batch_size=batch_size, verbose=0)\n",
    "        return accuracy, history\n",
    "\n",
    "def summarize_results(scores):\n",
    "        print(scores)\n",
    "        m, s = mean(scores), std(scores)\n",
    "        print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "def run_experiment(repeats=10):\n",
    "   \n",
    "        build_model()\n",
    "        \n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score, history = evaluate_model(trainX, trainy, testX, testy)\n",
    "            score = score * 100.0\n",
    "            print('>#%d: %.3f' % (r+1, score))\n",
    "            scores.append(score)\n",
    "#             plt.plot(history.history['loss'])\n",
    "#             plt.plot(history.history['val_loss'])\n",
    "#             plt.title('Training Loss VS Validation Loss')\n",
    "#             plt.ylabel('Loss')\n",
    "#             plt.xlabel('epoch')\n",
    "#             plt.legend(['train', 'val'], loc='upper left')\n",
    "#             plt.show()\n",
    "        # summarize results\n",
    "        summarize_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initialize the SPI and TERMIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spi_init():\n",
    "        spi.open(0,0)\n",
    "        spi.max_speed_hz =1350000\n",
    "        spi2.open(0,1)\n",
    "        spi2.max_speed_hz =1350000\n",
    "        \n",
    "def termios_init():\n",
    "        newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO\n",
    "        termios.tcsetattr(fd, termios.TCSANOW, newattr)\n",
    "        fcntl.fcntl(fd, fcntl.F_SETFL, oldflags | os.O_NONBLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Timer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatedTimer(object):\n",
    "  def __init__(self, interval, function, *args, **kwargs):\n",
    "    self._timer = None\n",
    "    self.interval = interval\n",
    "    self.function = function\n",
    "    self.args = args\n",
    "    self.kwargs = kwargs\n",
    "    self.is_running = False\n",
    "    self.next_call = time.time()\n",
    "    self.start()\n",
    "\n",
    "  def _run(self):\n",
    "    self.is_running = False\n",
    "    self.start()\n",
    "    self.function(*self.args, **self.kwargs)\n",
    "\n",
    "  def start(self):\n",
    "    if not self.is_running:\n",
    "      self.next_call += self.interval\n",
    "      self._timer = threading.Timer(self.next_call - time.time(), self._run)\n",
    "      self._timer.start()\n",
    "      self.is_running = True\n",
    "\n",
    "  def stop(self):\n",
    "    self._timer.cancel()\n",
    "    self.is_running = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Read Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char():\n",
    "    fd = sys.stdin.fileno()\n",
    "    old_settings = termios.tcgetattr(fd)\n",
    "    try:\n",
    "        tty.setraw(sys.stdin.fileno())\n",
    "        ch = sys.stdin.read(1)\n",
    "    finally:\n",
    "        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n",
    "    return ch\n",
    "\n",
    "\n",
    "def analogInput_CE0(channel,spi):\n",
    "    adc = spi.xfer2([1, (8+channel)<<4, 0])\n",
    "    data = ((adc[1]&3) <<8) + adc[2]\n",
    "    return data\n",
    "\n",
    "def analogInput_CE1(channel,spi2):\n",
    "    adc = spi2.xfer2([1, (8+channel)<<4, 0])\n",
    "    data = ((adc[1]&3) <<8) + adc[2]\n",
    "    return data\n",
    "\n",
    "def read_data():\n",
    "        if len(output)  < 500:\n",
    "            aux = []\n",
    "#             aux.append(time.time())\n",
    "            aux.append(analogInput_CE1(2,spi2))\n",
    "            aux.append(analogInput_CE0(3,spi))\n",
    "            aux.append(analogInput_CE0(7,spi))\n",
    "            aux.append(analogInput_CE1(3,spi2))\n",
    "            aux.append(analogInput_CE1(1,spi2))\n",
    "            aux.append(analogInput_CE0(5,spi))\n",
    "            aux.append(analogInput_CE0(1,spi))\n",
    "            aux.append(analogInput_CE0(2,spi))\n",
    "            aux.append(analogInput_CE0(6,spi))\n",
    "            '''aux.append(analogInput_CE0(0,spi))\n",
    "            aux.append(analogInput_CE0(1,spi))\n",
    "            aux.append(analogInput_CE0(2,spi))\n",
    "            aux.append(analogInput_CE0(3,spi))\n",
    "            aux.append(analogInput_CE1(0,spi2))\n",
    "            aux.append(analogInput_CE1(1,spi2))\n",
    "            aux.append(analogInput_CE1(2,spi2))\n",
    "            aux.append(analogInput_CE1(3,spi2))\n",
    "            aux.append(analogInput_CE1(4,spi2))'''\n",
    "            output.append(aux)\n",
    "#         print('output is : ', output)\n",
    "    \n",
    "\n",
    "# def get_real_data():\n",
    "#         i = 0\n",
    "#         real_data = []\n",
    "#         while i < 500:\n",
    "#             aux = []\n",
    "# #             aux.append(time.time())\n",
    "#             aux.append(analogInput_CE0(0,spi))\n",
    "#             aux.append(analogInput_CE0(1,spi))\n",
    "#             aux.append(analogInput_CE0(2,spi))\n",
    "#             aux.append(analogInput_CE0(3,spi))\n",
    "#             aux.append(analogInput_CE1(0,spi2))\n",
    "#             aux.append(analogInput_CE1(1,spi2))\n",
    "#             aux.append(analogInput_CE1(2,spi2))\n",
    "#             aux.append(analogInput_CE1(3,spi2))\n",
    "#             aux.append(analogInput_CE1(4,spi2))\n",
    "#     #         print('from the CE1_C5: ',aux)\n",
    "#             real_data.append(aux)\n",
    "#             i+=1\n",
    "\n",
    "#         return real_data_3D\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 80)                21840     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 29,130\n",
      "Trainable params: 29,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      ">#1: 100.000\n",
      ">#2: 100.000\n",
      ">#3: 100.000\n",
      ">#4: 100.000\n",
      ">#5: 100.000\n",
      ">#6: 100.000\n",
      ">#7: 100.000\n",
      ">#8: 100.000\n",
      ">#9: 100.000\n",
      ">#10: 100.000\n",
      "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Accuracy: 100.000% (+/-0.000)\n",
      "Interval is :  12833.48143696785\n"
     ]
    }
   ],
   "source": [
    "    # Training model\n",
    "prev_time = time.time()\n",
    "verbose, epochs, batch_size, num_Neurons = 0, 40, 128, 100\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]    \n",
    "model = Sequential() \n",
    "run_experiment()\n",
    "print('Interval is : ', time.time() - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model\n",
    "# filepath = './saved_model'\n",
    "# save_model(model, filepath, save_format='h5')\n",
    "model = load_model('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "start get input\n",
      "label is  3\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  9\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "m\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  9\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  9\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  9\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  4\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  0\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  2\n",
      "n\n",
      "start get input\n",
      "label is  2\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  8\n",
      "n\n",
      "start get input\n",
      "label is  1\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  5\n",
      "n\n",
      "start get input\n",
      "label is  6\n",
      "n\n",
      "start get input\n",
      "label is  6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    \n",
    "    global spi, spi2, output,fd, oldterm, newattr, oldflags, real_data_3D\n",
    "    spi = spidev.SpiDev()\n",
    "    spi2 = spidev.SpiDev()\n",
    "    output = []\n",
    "#     fd = sys.stdin.fileno()\n",
    "#     oldterm = termios.tcgetattr(fd)\n",
    "#     oldflags = fcntl.fcntl(fd, fcntl.F_GETFL)\n",
    "#     newattr = termios.tcgetattr(fd)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range = (0, 100), copy = True)\n",
    "    spi_init()\n",
    "#     termios_init()\n",
    "    RepeatedTimer(0.01,read_data).start()\n",
    "    while 1:\n",
    "        inkey = input()\n",
    "        if inkey == 'n':\n",
    "            print('start get input')\n",
    "            output = []\n",
    "            sleep(5.5)\n",
    "            output_3D = []\n",
    "            output_3D.append(min_max_scaler.fit_transform(output[0:500]))\n",
    "            real_data_3D = np.array(output_3D)\n",
    "#             real_data_3D = min_max_scaler.fit_transform()\n",
    "#             print(real_data_3D.shape)\n",
    "            real_data_3D.reshape((-1, 500, 9))\n",
    "#             print(real_data_3D)\n",
    "            label = model.predict(real_data_3D)\n",
    "#             print(\"label is \", label)\n",
    "            print('label is ', np.argmax(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
